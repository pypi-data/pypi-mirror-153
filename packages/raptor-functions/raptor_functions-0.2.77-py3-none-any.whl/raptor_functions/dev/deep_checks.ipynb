{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data -> (X,y) with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptor_functions.supervised.datasets import get_data\n",
    "df = get_data('handheld_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from boruta import BorutaPy\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import (\n",
    "    ComprehensiveFCParameters,\n",
    "    extract_features,\n",
    ")\n",
    "from tsfresh import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"exp_unique_id\",\n",
    "    \"timesteps\",\n",
    "    \"sensor_1\",\n",
    "    \"sensor_2\",\n",
    "    \"sensor_3\",\n",
    "    \"sensor_4\",\n",
    "    \"sensor_5\",\n",
    "    \"sensor_6\",\n",
    "    \"sensor_7\",\n",
    "    \"sensor_8\",\n",
    "    \"sensor_9\",\n",
    "    \"sensor_10\",\n",
    "    \"sensor_11\",\n",
    "    \"sensor_12\",\n",
    "    \"sensor_13\",\n",
    "    \"sensor_14\",\n",
    "    \"sensor_15\",\n",
    "    \"sensor_16\",\n",
    "    \"sensor_17\",\n",
    "    \"sensor_18\",\n",
    "    \"sensor_19\",\n",
    "    \"sensor_20\",\n",
    "    \"sensor_21\",\n",
    "    \"sensor_22\",\n",
    "    \"sensor_23\",\n",
    "    \"sensor_24\",\n",
    "]\n",
    "\n",
    "TARGET_COL = \"result\"\n",
    "\n",
    "unique_id=\"exp_unique_id\"\n",
    "label=\"result\"\n",
    "timesteps=\"timesteps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_settings = ComprehensiveFCParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.groupby(unique_id).first()[label]\n",
    "X = df.drop(label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:22<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "features = [col for col in X if col.startswith('sensor')]\n",
    "features = [unique_id, timesteps] + features\n",
    "\n",
    "X = X[features]\n",
    "\n",
    "# X = df.drop(label, axis=1)\n",
    "# y = df.groupby(unique_id).first()[label]\n",
    "\n",
    "X = extract_features(\n",
    "    X,\n",
    "    column_id=unique_id,\n",
    "    column_sort=timesteps,\n",
    "    default_fc_parameters=extraction_settings,\n",
    "    # we impute = remove all NaN features automatically\n",
    "    impute_function=impute,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_1__variance_larger_than_standard_deviation</th>\n",
       "      <th>sensor_1__has_duplicate_max</th>\n",
       "      <th>sensor_1__has_duplicate_min</th>\n",
       "      <th>sensor_1__has_duplicate</th>\n",
       "      <th>sensor_1__sum_values</th>\n",
       "      <th>sensor_1__abs_energy</th>\n",
       "      <th>sensor_1__mean_abs_change</th>\n",
       "      <th>sensor_1__mean_change</th>\n",
       "      <th>sensor_1__mean_second_derivative_central</th>\n",
       "      <th>sensor_1__median</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_24__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>sensor_24__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>sensor_24__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>sensor_24__matrix_profile__feature_\"min\"__threshold_0.98</th>\n",
       "      <th>sensor_24__matrix_profile__feature_\"max\"__threshold_0.98</th>\n",
       "      <th>sensor_24__matrix_profile__feature_\"mean\"__threshold_0.98</th>\n",
       "      <th>sensor_24__matrix_profile__feature_\"median\"__threshold_0.98</th>\n",
       "      <th>sensor_24__matrix_profile__feature_\"25\"__threshold_0.98</th>\n",
       "      <th>sensor_24__matrix_profile__feature_\"75\"__threshold_0.98</th>\n",
       "      <th>sensor_24__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15693.250</td>\n",
       "      <td>1.962165e+06</td>\n",
       "      <td>1.147378</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>131.1840</td>\n",
       "      <td>...</td>\n",
       "      <td>4.373100</td>\n",
       "      <td>4.569595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.171420</td>\n",
       "      <td>3.822228</td>\n",
       "      <td>2.409795</td>\n",
       "      <td>2.474262</td>\n",
       "      <td>1.771601</td>\n",
       "      <td>2.914718</td>\n",
       "      <td>155.948143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15906.505</td>\n",
       "      <td>2.001377e+06</td>\n",
       "      <td>0.895402</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>131.1210</td>\n",
       "      <td>...</td>\n",
       "      <td>4.400694</td>\n",
       "      <td>4.604489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842265</td>\n",
       "      <td>3.331958</td>\n",
       "      <td>1.880553</td>\n",
       "      <td>1.853738</td>\n",
       "      <td>1.349697</td>\n",
       "      <td>2.452201</td>\n",
       "      <td>156.120286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15674.239</td>\n",
       "      <td>1.960253e+06</td>\n",
       "      <td>1.115709</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>131.4975</td>\n",
       "      <td>...</td>\n",
       "      <td>4.273651</td>\n",
       "      <td>4.507078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781496</td>\n",
       "      <td>4.026202</td>\n",
       "      <td>2.332053</td>\n",
       "      <td>2.333184</td>\n",
       "      <td>1.543296</td>\n",
       "      <td>3.029155</td>\n",
       "      <td>158.410286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15502.825</td>\n",
       "      <td>1.904814e+06</td>\n",
       "      <td>0.942016</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>128.7030</td>\n",
       "      <td>...</td>\n",
       "      <td>4.504330</td>\n",
       "      <td>4.642867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936207</td>\n",
       "      <td>3.382332</td>\n",
       "      <td>2.014803</td>\n",
       "      <td>2.100663</td>\n",
       "      <td>1.232587</td>\n",
       "      <td>2.590493</td>\n",
       "      <td>156.301571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16154.553</td>\n",
       "      <td>2.069512e+06</td>\n",
       "      <td>1.050535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>133.5880</td>\n",
       "      <td>...</td>\n",
       "      <td>4.336223</td>\n",
       "      <td>4.530518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913677</td>\n",
       "      <td>3.611633</td>\n",
       "      <td>2.139663</td>\n",
       "      <td>2.118371</td>\n",
       "      <td>1.551142</td>\n",
       "      <td>2.609582</td>\n",
       "      <td>158.603143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18936 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_1__variance_larger_than_standard_deviation  \\\n",
       "0                                                1.0   \n",
       "1                                                1.0   \n",
       "2                                                1.0   \n",
       "3                                                1.0   \n",
       "4                                                1.0   \n",
       "\n",
       "   sensor_1__has_duplicate_max  sensor_1__has_duplicate_min  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          1.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   sensor_1__has_duplicate  sensor_1__sum_values  sensor_1__abs_energy  \\\n",
       "0                      1.0             15693.250          1.962165e+06   \n",
       "1                      1.0             15906.505          2.001377e+06   \n",
       "2                      1.0             15674.239          1.960253e+06   \n",
       "3                      1.0             15502.825          1.904814e+06   \n",
       "4                      1.0             16154.553          2.069512e+06   \n",
       "\n",
       "   sensor_1__mean_abs_change  sensor_1__mean_change  \\\n",
       "0                   1.147378               0.002984   \n",
       "1                   0.895402              -0.003984   \n",
       "2                   1.115709              -0.004008   \n",
       "3                   0.942016               0.000976   \n",
       "4                   1.050535               0.000000   \n",
       "\n",
       "   sensor_1__mean_second_derivative_central  sensor_1__median  ...  \\\n",
       "0                                 -0.005024          131.1840  ...   \n",
       "1                                  0.003008          131.1210  ...   \n",
       "2                                  0.003028          131.4975  ...   \n",
       "3                                  0.005905          128.7030  ...   \n",
       "4                                 -0.003599          133.5880  ...   \n",
       "\n",
       "   sensor_24__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                           4.373100    \n",
       "1                                           4.400694    \n",
       "2                                           4.273651    \n",
       "3                                           4.504330    \n",
       "4                                           4.336223    \n",
       "\n",
       "   sensor_24__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                           4.569595    \n",
       "1                                           4.604489    \n",
       "2                                           4.507078    \n",
       "3                                           4.642867    \n",
       "4                                           4.530518    \n",
       "\n",
       "   sensor_24__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                0.0              \n",
       "1                                                0.0              \n",
       "2                                                0.0              \n",
       "3                                                0.0              \n",
       "4                                                0.0              \n",
       "\n",
       "   sensor_24__matrix_profile__feature_\"min\"__threshold_0.98  \\\n",
       "0                                           1.171420          \n",
       "1                                           0.842265          \n",
       "2                                           0.781496          \n",
       "3                                           0.936207          \n",
       "4                                           0.913677          \n",
       "\n",
       "   sensor_24__matrix_profile__feature_\"max\"__threshold_0.98  \\\n",
       "0                                           3.822228          \n",
       "1                                           3.331958          \n",
       "2                                           4.026202          \n",
       "3                                           3.382332          \n",
       "4                                           3.611633          \n",
       "\n",
       "   sensor_24__matrix_profile__feature_\"mean\"__threshold_0.98  \\\n",
       "0                                           2.409795           \n",
       "1                                           1.880553           \n",
       "2                                           2.332053           \n",
       "3                                           2.014803           \n",
       "4                                           2.139663           \n",
       "\n",
       "   sensor_24__matrix_profile__feature_\"median\"__threshold_0.98  \\\n",
       "0                                           2.474262             \n",
       "1                                           1.853738             \n",
       "2                                           2.333184             \n",
       "3                                           2.100663             \n",
       "4                                           2.118371             \n",
       "\n",
       "   sensor_24__matrix_profile__feature_\"25\"__threshold_0.98  \\\n",
       "0                                           1.771601         \n",
       "1                                           1.349697         \n",
       "2                                           1.543296         \n",
       "3                                           1.232587         \n",
       "4                                           1.551142         \n",
       "\n",
       "   sensor_24__matrix_profile__feature_\"75\"__threshold_0.98  \\\n",
       "0                                           2.914718         \n",
       "1                                           2.452201         \n",
       "2                                           3.029155         \n",
       "3                                           2.590493         \n",
       "4                                           2.609582         \n",
       "\n",
       "   sensor_24__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                         155.948143   \n",
       "1                                         156.120286   \n",
       "2                                         158.410286   \n",
       "3                                         156.301571   \n",
       "4                                         158.603143   \n",
       "\n",
       "[5 rows x 18936 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp_unique_id\n",
       "0    Control\n",
       "1      Covid\n",
       "2    Control\n",
       "3      Covid\n",
       "4    Control\n",
       "Name: result, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_binary = pd.get_dummies(y)\n",
    "# y_binary = y_binary['Covid']\n",
    "# y = y_binary\n",
    "# y = y.to_frame()\n",
    "# y = y.rename(columns = {'Covid':'result'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X,y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test datasets + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train,y_train], axis=1)\n",
    "df_test = pd.concat([X_test,y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# model = xgb.XGBRegressor()\n",
    "# model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular import Dataset\n",
    "\n",
    "# We explicitly state that this dataset has no categorical features, otherwise they will be automatically inferred\n",
    "# If the dataset has categorical features, the best practice is to pass a list with their names\n",
    "\n",
    "ds_train = Dataset(df_train, label=label_col, cat_features=[])\n",
    "ds_test =  Dataset(df_test,  label=label_col, cat_features=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Data: Single Dataset Validation\n",
    "\n",
    "When you start working with a new dataset, you have only a single dataset (no train-test split), and you probably don’t have a model. As part of your EDA you want to ensure your data’s integrity, and have it ready for your needs. For example, you want to know if there are many duplicate samples, problems with string or categorical features, significant outliers, inconsistent labels, etc.\n",
    "\n",
    "For these purposes you can use the deepchecks.tabular.suites.single_dataset_integrity() suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d404ae1ae6c44e7aa73ec6eac07bb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Single Dataset Integrity Suite:   0%|          | 0/8 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import single_dataset_integrity\n",
    "suite = single_dataset_integrity() \n",
    "suite_result = suite.run(df)\n",
    "suite_result.save_as_html('df_integrify.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13602d636db345de9ad480dfbe07902e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Single Dataset Integrity Suite:   0%|          | 0/8 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite_result = suite.run(df_0)\n",
    "suite_result.save_as_html('df0_integrify')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Splitting the Data: Train-Test Validation\n",
    "\n",
    "When you split your data (for whichever purpose and manner), you have two or more separate datasets, however you might not have a model yet. Just before you continue working with your data you want to ensure that the splits are indeed representative as you want them to be. For example, you want to verify that the classes are balanced similarly, that there is no significant change in distributions between the features or labels in each of the classes, that there is no potential data leakage that may contaminate your model or perceived results, etc.\n",
    "\n",
    "For these purposes you can use the deepchecks.tabular.suites.train_test_validation() suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepchecks.tabular.suites import train_test_validation\n",
    "# suite = train_test_validation()\n",
    "# suite_result = suite.run(train_dataset=ds_train, test_dataset=ds_test, model=model)\n",
    "# suite_result.save_as_html('train_test_validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Training a Model: Analysis & Validation\n",
    "\n",
    "At this phase you have a trained model which you want to evaluate. Thus, you probably want to look at examine several performance metrics, compare it to various benchmarks and be able to construct a clear picture about the model’s performance. you may also want to try identify where it under-performs, and investigate to see if you discover any insights that you may use to improve its performance.\n",
    "\n",
    "For these purposes you can use the deepchecks.tabular.suites.model_evaluation() suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a2126d7af34d1a905c433c56c0f225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Evaluation Suite:   0%|          | 0/11 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import model_evaluation\n",
    "suite = model_evaluation()\n",
    "suite_result = suite.run(model=model, train_dataset=ds_train, test_dataset=ds_test)\n",
    "suite_result.save_as_html('model_evaluation.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Overview: Full Suite\n",
    "\n",
    "Here you want to have a quick overview of the project, and receive all of the insights that you can get, given a specific state of the model and the data.\n",
    "\n",
    "For this purpose you can use the deepchecks.tabular.suites.full_suite()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74a4378f8ce4e7daea9710282372200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Full Suite:   0%|          | 0/35 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielfiuzadosil/.local/lib/python3.7/site-packages/deepchecks/ppscore.py:139: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import full_suite\n",
    "suite = full_suite()\n",
    "suite_result = suite.run(train_dataset=ds_train, test_dataset=ds_test, model=model)\n",
    "suite_result.save_as_html('deep_check_full.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53c91a0ac8cebf87d6dc89d79689e596e7a69520b6d9c103a9f69d18d5e4e84f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv-3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
