import scrapy
# from scrapy.xcc_items.testitems import PicItem
# from scrapy.xcc_items.factoryitems import FactoryPlanItem
from ImageSpider.testitems import PicItem
from ImageSpider.factoryitems import FactoryPlanItem


# class ImgspiderSpider(scrapy.Spider):
#     '''多文件管道下,测试较复杂资源url拓展名能否自适应'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://www.piqsels.com/zh']

#     def parse(self, response):
#         imgurls = response.xpath("//figure//img/@data-src").extract()[0:5]
#         item = PicItem()
#         item['raw_img_url'] = 'https://up.enterdesk.com/edpic/cd/2e/39/cd2e39c1f11e92d9a42961cfd63def85.jpg'#'https://tse2-mm.cn.bing.net/th/id/OIP-C.sG7fXSQv_aB429rzCUXSsgHaE8?w=257&h=180&c=7&r=0&o=5&pid=1.7'
#         item['raw'] = 'https://tse1-mm.cn.bing.net/th/id/R-C.35d18ce0ca0e3cbda4ad343d38327f8a?rik=DpdG8%2fEM5ZOa4A&riu=http%3a%2f%2fwww.conventionbureau.com.br%2fturismo%2fwp-content%2fuploads%2fsites%2f4%2f2020%2f07%2fdfdf-2048x1536.jpg&ehk=NNAZvIMKtMt29POw1HVMK961iCCEjB%2bjOrYSwL0TJyQ%3d&risl=&pid=ImgRaw&r=0'
#         item['title'] = '测试较复杂资源url拓展名能否自适应'
#         yield item

# class ImgspiderSpider(scrapy.Spider):
#     '''单个文件管道下测试'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://www.piqsels.com/zh']

#     def parse(self, response):
#         imgurls = response.xpath("//figure//img/@data-src").extract()[0:5]
#         item = PicItem()
#         item['raw_img_url'] = 'https://up.enterdesk.com/edpic/cd/2e/39/cd2e39c1f11e92d9a42961cfd63def85.jpg'#'https://tse2-mm.cn.bing.net/th/id/OIP-C.sG7fXSQv_aB429rzCUXSsgHaE8?w=257&h=180&c=7&r=0&o=5&pid=1.7'
#         item['title'] = '单管道测试'
#         yield item

# class ImgspiderSpider(scrapy.Spider):
#     '''单个文件管道下测试,打开FILTER_EMPTY_ITEM,测试过滤资源链接为空的item'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://www.piqsels.com/zh']

#     def parse(self, response):
#         imgurls = response.xpath("//figure//img/@data-src").extract()[0:5]
#         item = PicItem()
#         item['raw_img_url'] = ''#'https://tse2-mm.cn.bing.net/th/id/OIP-C.sG7fXSQv_aB429rzCUXSsgHaE8?w=257&h=180&c=7&r=0&o=5&pid=1.7'
#         item['title'] = '单个文件管道下,资源链接为空测试'
#         yield item

# class ImgspiderSpider(scrapy.Spider):
#     '''多文件管道下测试,打开FILTER_EMPTY_ITEM,测试过滤资源链接为空的item (多个资源字段其中一个为空都将被drop)'''
#     '''记得打开多管道( ITEM_PIPELINES )和多配置( FILE_PIPE_CONFIG )'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://www.piqsels.com/zh']

#     def parse(self, response):
#         imgurls = response.xpath("//figure//img/@data-src").extract()[0:5]
#         item = PicItem()
#         item['raw_img_url'] = ''
#         item['raw'] = 'https://tse1-mm.cn.bing.net/th/id/R-C.35d18ce0ca0e3cbda4ad343d38327f8a?rik=DpdG8%2fEM5ZOa4A&riu=http%3a%2f%2fwww.conventionbureau.com.br%2fturismo%2fwp-content%2fuploads%2fsites%2f4%2f2020%2f07%2fdfdf-2048x1536.jpg&ehk=NNAZvIMKtMt29POw1HVMK961iCCEjB%2bjOrYSwL0TJyQ%3d&risl=&pid=ImgRaw&r=0'
#         item['title'] = '多文件管道下,资源链接为空测试'
#         yield item

# class ImgspiderSpider(scrapy.Spider):
#     '''多个文件管道下,测试资源类型为html,默认将返回空'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://cn.bing.com/']

#     def parse(self, response):
#         imgurls = response.xpath("//figure//img/@data-src").extract()[0:5]
#         item = PicItem()
#         item['raw_img_url'] = 'http://baidu.com'#'https://tse2-mm.cn.bing.net/th/id/OIP-C.sG7fXSQv_aB429rzCUXSsgHaE8?w=257&h=180&c=7&r=0&o=5&pid=1.7'
#         item['raw'] = 'https://tse1-mm.cn.bing.net/th/id/R-C.35d18ce0ca0e3cbda4ad343d38327f8a?rik=DpdG8%2fEM5ZOa4A&riu=http%3a%2f%2fwww.conventionbureau.com.br%2fturismo%2fwp-content%2fuploads%2fsites%2f4%2f2020%2f07%2fdfdf-2048x1536.jpg&ehk=NNAZvIMKtMt29POw1HVMK961iCCEjB%2bjOrYSwL0TJyQ%3d&risl=&pid=ImgRaw&r=0'
#         item['title'] = '多管道测试资源类型为html'
#         yield item

# class ImgspiderSpider(scrapy.Spider):
#     '''测试文件是否重复下载'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://www.piqsels.com/zh']

#     def parse(self, response):
#         imgurls = response.xpath("//figure//img/@data-src").extract()[0:5]
#         imgurls_other = response.xpath("//figure//img/@data-src").extract()[5:10]
#         for flag in ['第一遍','第二遍']: #同样的item 资源下载两遍
#             for img in imgurls: #测试
#                 item = PicItem()
#                 item['raw_img_url'] = img
#                 item['title'] = flag
#                 yield item

# class ImgspiderSpider(scrapy.Spider):
#     '''测试多种item 隔离问题'''
#     name = 'ImgSpiderduocanshu'
#     start_urls = ['https://www.enterdesk.com/special/baidu/']

#     def parse(self, response):
#         imgurls = response.xpath("//*[@id='auto_width_specialist_0']//dd/img/@src").extract()[0:5]
#         # imgurls_other = response.xpath("//figure//img/@data-src").extract()[5:10]
#         for img in imgurls: #测试
#             item = PicItem()
#             item_cate = FactoryPlanItem()
#             item['raw_img_url'] = img
#             item['title'] = item.__class__.__name__
#             item_cate['name'] = item_cate.__class__.__name__
#             # item_cate['image_url'] ='|'.join(imgurls_other )
#             yield item
#             # yield item_cate


class ImgspiderSpider(scrapy.Spider):
    '''测试多种item 隔离问题'''
    name = '$name'
    start_urls = ['http://www.datasheetcatalog.com/']
    # start_urls = ['https://www.enterdesk.com/special/baidu/']

    def parse(self, response):
        # imgurls = response.xpath("//*[@id='auto_width_specialist_0']//dd/img/@src").extract()[0:5]
        # # imgurls_other = response.xpath("//figure//img/@data-src").extract()[5:10]
        # for img in imgurls: #测试
        item = PicItem()
        item_cate = FactoryPlanItem(table_add='_dkfkd')
        # item['raw_img_url'] = 'http://pdf.datasheetcatalog.com/datasheets2/52/521020_1.pdf'
        item['raw_img_url'] = 'https://tse1-mm.cn.bing.net/th/id/R-C.35d18ce0ca0e3cbda4ad343d38327f8a?rik=DpdG8%2fEM5ZOa4A&riu=http%3a%2f%2fwww.conventionbureau.com.br%2fturismo%2fwp-content%2fuploads%2fsites%2f4%2f2020%2f07%2fdfdf-2048x1536.jpg&ehk=NNAZvIMKtMt29POw1HVMK961iCCEjB%2bjOrYSwL0TJyQ%3d&risl=&pid=ImgRaw&r=0'
        item['title'] = item.__class__.__name__
        item_cate['name'] = item_cate.__class__.__name__
        # item_cate['image_url'] ='|'.join(imgurls_other )
        yield item
        # yield item_cate

